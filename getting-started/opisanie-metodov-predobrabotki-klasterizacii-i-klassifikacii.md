---
icon: arrow-progress
---

# Описание методов предобработки, кластеризации и классификации

### Описание методов

#### 1) Предобработка текста

**Цель:** убрать шум, унифицировать лексику и подготовить тексты для эмбеддингов и витрины тем.

* **Нормализация терминов/англицизмов:** `normalize_anglicisms` (cashback→кэшбэк, push→пуш, UnionPay и пр.).
* **Лемматизация RU:** `normalize_ru` (pymorphy2): приведение к нач. форме, удаление служебных POS, стоп-слов и лишних чисел. Латиница/бренды сохраняются.
* **Сборка текста:** `prepare_text(title, text)` → два представления:
  * `docs_ctx` — «сырое» (title + text) для эмбеддингов;
  * `docs_clean` — очищенное (леммы) для именования тем.
* **Чанкинг длинных отзывов:** резка до `max_chars` (по умолчанию 1000), разрыв по пробелам и знакам препинания, без потери семантики.

**Ключевые параметры:** `max_chars`, список доменных стоп-слов (банк, карта, приложение, отделение…).

***

#### 2) Эмбеддинги и пуллинг

**Модель эмбеддингов:** `SentenceTransformer` (по умолчанию `BAAI/bge-m3`).

1. Кодируем каждый чанк отдельно.
2. Агрегируем чанки документа (пуллинг):
   * `max` (по умолчанию) — берёт максимум по измерению;
   * `mean` — среднее по чанкам;
   * `attn_len` — взвешивание по длине чанков.
3. L2-нормализация итогового вектора.

**Замена/ускорение:** поддерживается ONNX (`onnxruntime`) и квантование для CPU-инференса.

***

#### 3) Тематическая кластеризация (BERTopic)

**Задача:** сгруппировать отзывы по близким обсуждаемым темам и дать им интерпретируемые названия.

* **Векторизатор для названий тем:** `CountVectorizer(ngram_range=(1,3), min_df=3, max_df=0.4)` + доменные стоп-слова.
* **Кластеризация эмбеддингов:**
  * по умолчанию **KMeans** (BERTopic 0.17.x: передаём как `hdbscan_model=KMeans(...)`);
  * альтернатива **HDBSCAN** (для неоднородных кластеров); при избытке `-1` — включаем `reduce_outliers`.
* **Улучшение названий тем:** `update_topics(..., representation_model=MaximalMarginalRelevance(diversity≈0.6))` — снижает дубли и «словесный мусор».
* **Выходные артефакты:** `topic_info` (список тем, частоты, топ-слова), `doc_info` (тема по документу).

**Ключевые параметры:** `use_kmeans`, `n_clusters` (если KMeans), `min_topic_size`/`min_df`, список стоп-слов, `diversity` для MMR.

***

#### 4) Мультилейбл-классификация (zero-shot на эмбеддингах)

**Идея:** для каждого бизнес-класса создать «прототип» (средний вектор из нескольких фраз-синонимов), затем сопоставлять документы (или темы) с классами по косинусному сходству.

* **Прототипы классов:** в `src/final_classes.py` задаются 3–15 фраз на класс (в т.ч. негативные/разговорные варианты).\
  Эмбеддим фразы → усредняем ⇒ вектор класса.
* **Оценка документа:** эмбеддинг документа vs матрица векторов классов ⇒ косинусы.
* **Отбор меток:**
  * **Top-k** (по умолчанию `k=3`) или
  * **Порог по косинусу** (например, `≥0.3..0.4`) для независимого мультилейбла.
* **Квазивероятности:** `softmax` по косинусам с температурой `τ≈0.07` (функция `softmax_cos`) — удобно для сортировки и UI.

**Ключевые параметры:** `topk_classes`, порог косинуса, `τ` для softmax, состав фраз-прототипов.

***

#### 5) Классификация тональности (положительно/нейтрально/отрицательно)

**Варианты (поддерживаются оба; рекомендуем ❶):**

1. **Zero-shot тональность на эмбеддингах** (без отдельной модели):
   * Прототипы для классов `positive/neutral/negative` (по 10–30 коротких фраз на русском: «понравилось», «быстро решили»; «обычно», «как обычно»; «ужасно», «обман», «скрытые комиссии» и т.п.).
   * Эмбеддинг документа vs три вектора тональности ⇒ косинусы ⇒ argmax или порог.
   * Плюсы: быстрый, единый стек, легко дополнять доменной лексикой.
2. **Лёгкая супервизия** (если есть размеченные примеры):
   * Дообучаем линейный классификатор на эмбеддингах (LogReg/LinearSVM) или берём готовый small-ru-sentiment (Distil/RuBERT), конвертируем в ONNX.
   * Плюсы: выше качество при наличии разметки; Минусы: отдельный артефакт.

**Советы по качеству:** добавляйте негативные/саркастические формулировки в прототипы; при перекосе классов — калибруйте пороги.

***

#### 6) Метрики и валидация

* **Классификация тем (мультилейбл):** micro/macro F1, precision@k (на тестовой ручной валидации), coverage@k при пороговом отборе.
* **Тональность:** accuracy, macro-F1; дополнительно — confusion matrix (для нейтрали).
* **Кластеризация:** интерпретируемость по `topic_info`, доля «сомнительных» тем (низкий sim к top-1 классу), стабильность при ресемплинге.
* **Отчёты:** `artifacts/latest/bertopic_outputs.xlsx` → листы `topics_top3_classes`, `documents_topk`, `suspect_topics`.

***

#### 7) Краевые случаи и эвристики

* **Очень короткие отзывы** («норм», «плохо»): применяем тональность напрямую; темы можно помечать как `misc/прочее`.
* **Длинные смешанные отзывы:** чанкинг + `max`-пуллинг лучше ловит редкие негативные фрагменты; `mean` сглаживает.
* **Дубли/спам:** дедупликация по hash(title+text), игнор повторов в обучении.
* **Шумной класс `-1` при HDBSCAN:** включить `reduce_outliers` или перейти на KMeans.
* **Конфликт меток:** при близких косинусах — показывать обе (мультилейбл) или требовать порог.

***

#### 8) Быстрые настройки (рекомендуемые дефолты)

* `embedder_model="BAAI/bge-m3"`, `pooling="max"`, `max_chars=1000`
* BERTopic: KMeans `n_clusters≈50–120` (зависит от корпуса), `min_df=3`, `max_df=0.4`, MMR `diversity=0.6`
* Классы: `topk_classes=3`, `τ=0.07`; для порога косинуса начните с `0.35`
* Тональность zero-shot: по 15–25 прототипов на класс

***

#### 9) Где править и что сохраняется

* **Правки:** `src/utils_text.py` (очистка), `src/encode.py` (чанкинг/пуллинг), `src/final_classes.py` (лексикон классов и тональности).
* **Артефакты:** `artifacts/latest/{bertopic_model/, embedder/, class_vecs.npy, class_names.json, bertopic_outputs.xlsx}`.
* Все параметры/артефакты логируются в **MLflow** для воспроизводимости.
